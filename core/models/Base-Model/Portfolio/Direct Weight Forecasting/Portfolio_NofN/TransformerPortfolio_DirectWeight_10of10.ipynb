{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4JJZsmd8vbp",
        "outputId": "ff0d1b21-d16e-460d-81e8-327099292c66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connect to Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoJfG_zvPvm4",
        "outputId": "5685cdc0-7072-4fa3-ea36-4d8f63c5530b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/Crypro_21.rar\n",
            "\n",
            "Creating    content                                                   OK\n",
            "Extracting  content/data_TSTUSDT.pkl                                     \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  content/data_TRXUSDT.pkl                                     \b\b\b\b  9%\b\b\b\b\b  OK \n",
            "Extracting  content/data_OGUSDT.pkl                                      \b\b\b\b 13%\b\b\b\b\b  OK \n",
            "Extracting  content/data_XRPUSDT.pkl                                     \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  content/data_FORMUSDT.pkl                                    \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  content/data_USDCUSDT.pkl                                    \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  content/data_BTCUSDT.pkl                                     \b\b\b\b 34%\b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  content/data_WUSDT.pkl                                       \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  content/data_TUSDT.pkl                                       \b\b\b\b 43%\b\b\b\b\b  OK \n",
            "Extracting  content/data_ETHUSDT.pkl                                     \b\b\b\b 50%\b\b\b\b\b  OK \n",
            "Extracting  content/data_SEIUSDT.pkl                                     \b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  content/data_ARKUSDT.pkl                                     \b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  content/data_MEUSDT.pkl                                      \b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Extracting  content/data_HOTUSDT.pkl                                     \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  content/data_XLMUSDT.pkl                                     \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  content/data_TIAUSDT.pkl                                     \b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  content/data_HBARUSDT.pkl                                    \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  content/data_GMTUSDT.pkl                                     \b\b\b\b 86%\b\b\b\b\b  OK \n",
            "Extracting  content/data_SUSDT.pkl                                       \b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  content/data_DUSDT.pkl                                       \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  content/data_JSTUSDT.pkl                                     \b\b\b\b100%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ],
      "source": [
        "!unrar x \"/content/drive/MyDrive/Crypro_21.rar\" \"content/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtD3YCrnC6me"
      },
      "source": [
        "Loading Embeded news based on Finbert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0hnx5gF4QxYs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "data_news_path = '../../../dataset/Crypto_1min/'\n",
        "df_news = pd.read_pickle('/content/drive/MyDrive/news_20crypto_embed_finbert.pickle')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rutbK1ceC-38"
      },
      "source": [
        "Embedding No News sentence for using in timestamp with no news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvGCYGIUEF3I",
        "outputId": "14f4e7d5-8154-4789-858d-54fb9f8a8712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding shape: (768,)\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# Load FinBERT model and tokenizer\n",
        "model_name = \"yiyanghkust/finbert-tone\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Your input news text\n",
        "text = \"No news.\"\n",
        "\n",
        "# Tokenize and encode the text\n",
        "inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
        "\n",
        "# Get the model output\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Use the [CLS] token embedding as sentence embedding\n",
        "cls_embedding = outputs.last_hidden_state[:, 0, :]  # Shape: [1, 768]\n",
        "\n",
        "# Convert to numpy array if needed\n",
        "embedding_vector = cls_embedding.squeeze().numpy()\n",
        "\n",
        "print(\"Embedding shape:\", embedding_vector.shape)\n",
        "# print(\"Embedding vector:\", embedding_vector)\n",
        "no_news_vector = list(embedding_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOuH6VDZDUqa"
      },
      "source": [
        "Loading OHLCV of multi stocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1SdJSHGWZM4G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "data_crypto_path = '/content/content/'\n",
        "list_crypto = [x[5:-4] for x in os.listdir(data_crypto_path) if 'data_' in x and 'FORMUSDT' not in x]\n",
        "# list_crypto = list_crypto[4:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUCTbnXmeky4",
        "outputId": "c57bfdf2-7f8a-48d5-f35a-2f47f4a8497a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(list_crypto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GOw-0uvMOWn8"
      },
      "outputs": [],
      "source": [
        "list_crypto = ['BTCUSDT', 'ETHUSDT', 'XRPUSDT', 'TRXUSDT', 'SEIUSDT',\n",
        " 'HBARUSDT', 'XLMUSDT', 'TIAUSDT', 'ARKUSDT', 'JSTUSDT']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjVhl2HuvTxA",
        "outputId": "c0e6d30f-3fca-49b3-edcf-75dee13e5c01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BTCUSDT 131041\n",
            "ETHUSDT 131041\n",
            "XRPUSDT 131041\n",
            "TRXUSDT 131041\n",
            "SEIUSDT 131041\n",
            "HBARUSDT 131041\n",
            "XLMUSDT 131041\n",
            "TIAUSDT 131041\n",
            "ARKUSDT 131041\n",
            "JSTUSDT 131041\n"
          ]
        }
      ],
      "source": [
        "list_data = []\n",
        "shifted_window = 30\n",
        "selected_f_asset = ['open', 'high', 'low', 'close', 'volume',\n",
        "    'quoteAssetVolume', 'numberOfTrades', 'takerBuyBaseVol',\n",
        "       'takerBuyQuoteVol']\n",
        "selected_f_asset = ['close', 'volume', 'numberOfTrades', 'prev_return', 'prev_volatility', 'return', 'volatility']\n",
        "selected_f_all = []\n",
        "list_target = []\n",
        "\n",
        "for symb in list_crypto:\n",
        "  df = pd.read_pickle(data_crypto_path+'data_{}.pkl'.format(symb))\n",
        "  print(symb, len(df))\n",
        "  df['return'] = 100*((df['close'].shift(-1)/df['close'])-1)\n",
        "  df['prev_return'] = 100*((df['close']/df['close'].shift(shifted_window))-1)\n",
        "  df['volatility'] = 100*df['close'].rolling(shifted_window).std().shift(-shifted_window)\n",
        "  df['prev_volatility'] = 100*df['close'].rolling(shifted_window).std()\n",
        "  df = df[selected_f_asset].rename(columns={x:symb+'_'+x for x in selected_f_asset})\n",
        "  selected_f_all.extend(list(df.columns))\n",
        "\n",
        "  df[symb+'_return'] = df[symb+'_'+'return']\n",
        "  df[symb+'_volatility'] = df[symb+'_'+'volatility']\n",
        "  list_target.append(symb+'_return')\n",
        "  list_target.append(symb+'_volatility')\n",
        "  list_data.append(df.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLNlIK2ob6wf",
        "outputId": "79a1c35f-779f-4949-a0f3-c70f06d4f124"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(selected_f_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "JOqUDUbXWGYb",
        "outputId": "7315a779-5583-4354-d84e-0571c4079aac"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d4969512-27be-4775-95f1-8040f199b7e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BTCUSDT_close</th>\n",
              "      <th>BTCUSDT_volume</th>\n",
              "      <th>BTCUSDT_numberOfTrades</th>\n",
              "      <th>BTCUSDT_prev_return</th>\n",
              "      <th>BTCUSDT_prev_volatility</th>\n",
              "      <th>BTCUSDT_return</th>\n",
              "      <th>BTCUSDT_volatility</th>\n",
              "      <th>ETHUSDT_close</th>\n",
              "      <th>ETHUSDT_volume</th>\n",
              "      <th>ETHUSDT_numberOfTrades</th>\n",
              "      <th>...</th>\n",
              "      <th>JSTUSDT_close</th>\n",
              "      <th>JSTUSDT_volume</th>\n",
              "      <th>JSTUSDT_numberOfTrades</th>\n",
              "      <th>JSTUSDT_prev_return</th>\n",
              "      <th>JSTUSDT_prev_volatility</th>\n",
              "      <th>JSTUSDT_return</th>\n",
              "      <th>JSTUSDT_volatility</th>\n",
              "      <th>dateTime</th>\n",
              "      <th>time</th>\n",
              "      <th>return</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>91785.18</td>\n",
              "      <td>44.25582000</td>\n",
              "      <td>9784</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.057275</td>\n",
              "      <td>30532.801818</td>\n",
              "      <td>2522.98</td>\n",
              "      <td>1236.00450000</td>\n",
              "      <td>7010</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03331</td>\n",
              "      <td>18269.00000000</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.030021</td>\n",
              "      <td>0.008186</td>\n",
              "      <td>2025-02-25 00:00:00</td>\n",
              "      <td>2025-02-25 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>91837.75</td>\n",
              "      <td>29.64367000</td>\n",
              "      <td>7048</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.134171</td>\n",
              "      <td>30363.719702</td>\n",
              "      <td>2525.15</td>\n",
              "      <td>609.72690000</td>\n",
              "      <td>4877</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03332</td>\n",
              "      <td>2854.40000000</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007935</td>\n",
              "      <td>2025-02-25 00:01:00</td>\n",
              "      <td>2025-02-25 00:01:00</td>\n",
              "      <td>0.000573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>91960.97</td>\n",
              "      <td>70.22032000</td>\n",
              "      <td>6386</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.106784</td>\n",
              "      <td>29798.433752</td>\n",
              "      <td>2529.97</td>\n",
              "      <td>672.80150000</td>\n",
              "      <td>3844</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03332</td>\n",
              "      <td>89531.30000000</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.030012</td>\n",
              "      <td>0.007655</td>\n",
              "      <td>2025-02-25 00:02:00</td>\n",
              "      <td>2025-02-25 00:02:00</td>\n",
              "      <td>0.001342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91862.77</td>\n",
              "      <td>50.83532000</td>\n",
              "      <td>4539</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.209748</td>\n",
              "      <td>29594.091863</td>\n",
              "      <td>2525.85</td>\n",
              "      <td>595.41120000</td>\n",
              "      <td>3903</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03333</td>\n",
              "      <td>328.80000000</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.120012</td>\n",
              "      <td>0.007285</td>\n",
              "      <td>2025-02-25 00:03:00</td>\n",
              "      <td>2025-02-25 00:03:00</td>\n",
              "      <td>-0.001068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91670.09</td>\n",
              "      <td>62.93148000</td>\n",
              "      <td>11779</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.141704</td>\n",
              "      <td>29585.077527</td>\n",
              "      <td>2516.18</td>\n",
              "      <td>1280.56490000</td>\n",
              "      <td>9605</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03329</td>\n",
              "      <td>18030.80000000</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.030039</td>\n",
              "      <td>0.007097</td>\n",
              "      <td>2025-02-25 00:04:00</td>\n",
              "      <td>2025-02-25 00:04:00</td>\n",
              "      <td>-0.002097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131036</th>\n",
              "      <td>109394.14</td>\n",
              "      <td>1.80238000</td>\n",
              "      <td>514</td>\n",
              "      <td>0.142651</td>\n",
              "      <td>7155.315753</td>\n",
              "      <td>0.013666</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2562.98</td>\n",
              "      <td>50.44800000</td>\n",
              "      <td>421</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03559</td>\n",
              "      <td>1595.40000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.140687</td>\n",
              "      <td>0.002047</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025-05-26 23:56:00</td>\n",
              "      <td>2025-05-26 23:56:00</td>\n",
              "      <td>-0.000065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131037</th>\n",
              "      <td>109409.09</td>\n",
              "      <td>5.64688000</td>\n",
              "      <td>698</td>\n",
              "      <td>0.180025</td>\n",
              "      <td>6913.379611</td>\n",
              "      <td>0.007742</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2563.49</td>\n",
              "      <td>77.09600000</td>\n",
              "      <td>508</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03559</td>\n",
              "      <td>836.40000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.168871</td>\n",
              "      <td>0.001946</td>\n",
              "      <td>-0.028098</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025-05-26 23:57:00</td>\n",
              "      <td>2025-05-26 23:57:00</td>\n",
              "      <td>0.000137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131038</th>\n",
              "      <td>109417.56</td>\n",
              "      <td>0.52540000</td>\n",
              "      <td>224</td>\n",
              "      <td>0.187661</td>\n",
              "      <td>6626.350282</td>\n",
              "      <td>0.015747</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2563.20</td>\n",
              "      <td>60.38830000</td>\n",
              "      <td>171</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03558</td>\n",
              "      <td>1531.20000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.112549</td>\n",
              "      <td>0.001864</td>\n",
              "      <td>0.028106</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025-05-26 23:58:00</td>\n",
              "      <td>2025-05-26 23:58:00</td>\n",
              "      <td>0.000077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131039</th>\n",
              "      <td>109434.79</td>\n",
              "      <td>3.88664000</td>\n",
              "      <td>1349</td>\n",
              "      <td>0.197704</td>\n",
              "      <td>6365.351309</td>\n",
              "      <td>-0.038626</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2563.70</td>\n",
              "      <td>99.02600000</td>\n",
              "      <td>711</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03559</td>\n",
              "      <td>7002.90000000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.168871</td>\n",
              "      <td>0.001714</td>\n",
              "      <td>-0.028098</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025-05-26 23:59:00</td>\n",
              "      <td>2025-05-26 23:59:00</td>\n",
              "      <td>0.000157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131040</th>\n",
              "      <td>109392.52</td>\n",
              "      <td>2.73521000</td>\n",
              "      <td>1338</td>\n",
              "      <td>0.157278</td>\n",
              "      <td>5887.458809</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2562.30</td>\n",
              "      <td>363.41840000</td>\n",
              "      <td>1449</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03558</td>\n",
              "      <td>14501.50000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.112549</td>\n",
              "      <td>0.001592</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025-05-27 00:00:00</td>\n",
              "      <td>2025-05-27 00:00:00</td>\n",
              "      <td>-0.000386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>131041 rows Ã— 73 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4969512-27be-4775-95f1-8040f199b7e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d4969512-27be-4775-95f1-8040f199b7e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d4969512-27be-4775-95f1-8040f199b7e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-439f4cc2-e2d3-4632-b3e7-96259b8a654c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-439f4cc2-e2d3-4632-b3e7-96259b8a654c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-439f4cc2-e2d3-4632-b3e7-96259b8a654c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        BTCUSDT_close BTCUSDT_volume  BTCUSDT_numberOfTrades  \\\n",
              "0            91785.18    44.25582000                    9784   \n",
              "1            91837.75    29.64367000                    7048   \n",
              "2            91960.97    70.22032000                    6386   \n",
              "3            91862.77    50.83532000                    4539   \n",
              "4            91670.09    62.93148000                   11779   \n",
              "...               ...            ...                     ...   \n",
              "131036      109394.14     1.80238000                     514   \n",
              "131037      109409.09     5.64688000                     698   \n",
              "131038      109417.56     0.52540000                     224   \n",
              "131039      109434.79     3.88664000                    1349   \n",
              "131040      109392.52     2.73521000                    1338   \n",
              "\n",
              "        BTCUSDT_prev_return  BTCUSDT_prev_volatility  BTCUSDT_return  \\\n",
              "0                       NaN                      NaN        0.057275   \n",
              "1                       NaN                      NaN        0.134171   \n",
              "2                       NaN                      NaN       -0.106784   \n",
              "3                       NaN                      NaN       -0.209748   \n",
              "4                       NaN                      NaN        0.141704   \n",
              "...                     ...                      ...             ...   \n",
              "131036             0.142651              7155.315753        0.013666   \n",
              "131037             0.180025              6913.379611        0.007742   \n",
              "131038             0.187661              6626.350282        0.015747   \n",
              "131039             0.197704              6365.351309       -0.038626   \n",
              "131040             0.157278              5887.458809             NaN   \n",
              "\n",
              "        BTCUSDT_volatility  ETHUSDT_close ETHUSDT_volume  \\\n",
              "0             30532.801818        2522.98  1236.00450000   \n",
              "1             30363.719702        2525.15   609.72690000   \n",
              "2             29798.433752        2529.97   672.80150000   \n",
              "3             29594.091863        2525.85   595.41120000   \n",
              "4             29585.077527        2516.18  1280.56490000   \n",
              "...                    ...            ...            ...   \n",
              "131036                 NaN        2562.98    50.44800000   \n",
              "131037                 NaN        2563.49    77.09600000   \n",
              "131038                 NaN        2563.20    60.38830000   \n",
              "131039                 NaN        2563.70    99.02600000   \n",
              "131040                 NaN        2562.30   363.41840000   \n",
              "\n",
              "        ETHUSDT_numberOfTrades  ...  JSTUSDT_close  JSTUSDT_volume  \\\n",
              "0                         7010  ...        0.03331  18269.00000000   \n",
              "1                         4877  ...        0.03332   2854.40000000   \n",
              "2                         3844  ...        0.03332  89531.30000000   \n",
              "3                         3903  ...        0.03333    328.80000000   \n",
              "4                         9605  ...        0.03329  18030.80000000   \n",
              "...                        ...  ...            ...             ...   \n",
              "131036                     421  ...        0.03559   1595.40000000   \n",
              "131037                     508  ...        0.03559    836.40000000   \n",
              "131038                     171  ...        0.03558   1531.20000000   \n",
              "131039                     711  ...        0.03559   7002.90000000   \n",
              "131040                    1449  ...        0.03558  14501.50000000   \n",
              "\n",
              "        JSTUSDT_numberOfTrades  JSTUSDT_prev_return  JSTUSDT_prev_volatility  \\\n",
              "0                           13                  NaN                      NaN   \n",
              "1                            4                  NaN                      NaN   \n",
              "2                            8                  NaN                      NaN   \n",
              "3                            1                  NaN                      NaN   \n",
              "4                           13                  NaN                      NaN   \n",
              "...                        ...                  ...                      ...   \n",
              "131036                       2             0.140687                 0.002047   \n",
              "131037                       2             0.168871                 0.001946   \n",
              "131038                       1             0.112549                 0.001864   \n",
              "131039                       5             0.168871                 0.001714   \n",
              "131040                       9             0.112549                 0.001592   \n",
              "\n",
              "       JSTUSDT_return  JSTUSDT_volatility            dateTime  \\\n",
              "0            0.030021            0.008186 2025-02-25 00:00:00   \n",
              "1            0.000000            0.007935 2025-02-25 00:01:00   \n",
              "2            0.030012            0.007655 2025-02-25 00:02:00   \n",
              "3           -0.120012            0.007285 2025-02-25 00:03:00   \n",
              "4            0.030039            0.007097 2025-02-25 00:04:00   \n",
              "...               ...                 ...                 ...   \n",
              "131036       0.000000                 NaN 2025-05-26 23:56:00   \n",
              "131037      -0.028098                 NaN 2025-05-26 23:57:00   \n",
              "131038       0.028106                 NaN 2025-05-26 23:58:00   \n",
              "131039      -0.028098                 NaN 2025-05-26 23:59:00   \n",
              "131040            NaN                 NaN 2025-05-27 00:00:00   \n",
              "\n",
              "                       time    return  \n",
              "0       2025-02-25 00:00:00       NaN  \n",
              "1       2025-02-25 00:01:00  0.000573  \n",
              "2       2025-02-25 00:02:00  0.001342  \n",
              "3       2025-02-25 00:03:00 -0.001068  \n",
              "4       2025-02-25 00:04:00 -0.002097  \n",
              "...                     ...       ...  \n",
              "131036  2025-05-26 23:56:00 -0.000065  \n",
              "131037  2025-05-26 23:57:00  0.000137  \n",
              "131038  2025-05-26 23:58:00  0.000077  \n",
              "131039  2025-05-26 23:59:00  0.000157  \n",
              "131040  2025-05-27 00:00:00 -0.000386  \n",
              "\n",
              "[131041 rows x 73 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.concat(list_data,axis=1)\n",
        "df = pd.read_pickle(data_crypto_path+'data_{}.pkl'.format('BTCUSDT'))\n",
        "df['return'] = df['close'].pct_change()\n",
        "data['dateTime'] = df['dateTime']\n",
        "data['time'] = data['dateTime'].astype(str).copy()\n",
        "data['return'] = df['close'].pct_change()\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulfB6WjhDelm"
      },
      "source": [
        "Preparing embedding of news (Handling multi news and no news)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuQaN9TBQVEy",
        "outputId": "ff4966c1-3515-4b99-8642-af8e02dcc972"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.18681939240390413"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['day'] = data['dateTime'].apply(lambda x:str(x)[:10])\n",
        "data[data['day']>='2025-05-10'].shape[0]/data.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZrcDQ89lGBgG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "df_news['embedding'] = df_news['embedding'].apply(lambda x: np.array(x))\n",
        "\n",
        "df_grouped = df_news[['time', 'embedding', 'count']].groupby('time')['embedding'].apply(\n",
        "    lambda x: np.mean(np.stack(x.values), axis=0)\n",
        ").reset_index()\n",
        "data_all = data.merge(df_grouped, on='time', how='left')\n",
        "data_all['embedding'] = data_all['embedding'].apply(\n",
        "    lambda x: no_news_vector if x is np.nan or x is None else x\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C3hYw_6e3jr",
        "outputId": "47afafec-6d20-4e6e-f1f1-e8ef1ad7f445"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['BTC', 'ETH', 'XRP', 'TRX', 'SEI', 'HBAR', 'XLM', 'TIA', 'ARK', 'JST']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_crypto_first = [x[:-4] for x in list_crypto]\n",
        "list_crypto_first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "w4FR3DMt-8PD"
      },
      "outputs": [],
      "source": [
        "data_all = data_all[data_all['time']>=df_news['time'].min()][data_all['time']<=df_news['time'].max()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lPXu_E1Dwq3"
      },
      "source": [
        "Showing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "KnoYdNDeA4KT",
        "outputId": "56a76a2b-fe22-42b0-b064-9d76f3d6fdc5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-510fd123-93ed-4020-af87-b3b16ec15bff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BTCUSDT_close</th>\n",
              "      <th>BTCUSDT_volume</th>\n",
              "      <th>BTCUSDT_numberOfTrades</th>\n",
              "      <th>BTCUSDT_prev_return</th>\n",
              "      <th>BTCUSDT_prev_volatility</th>\n",
              "      <th>BTCUSDT_return</th>\n",
              "      <th>BTCUSDT_volatility</th>\n",
              "      <th>ETHUSDT_close</th>\n",
              "      <th>ETHUSDT_volume</th>\n",
              "      <th>ETHUSDT_numberOfTrades</th>\n",
              "      <th>...</th>\n",
              "      <th>ARKUSDT_prev_volatility</th>\n",
              "      <th>ARKUSDT_return</th>\n",
              "      <th>ARKUSDT_volatility</th>\n",
              "      <th>JSTUSDT_close</th>\n",
              "      <th>JSTUSDT_volume</th>\n",
              "      <th>JSTUSDT_numberOfTrades</th>\n",
              "      <th>JSTUSDT_prev_return</th>\n",
              "      <th>JSTUSDT_prev_volatility</th>\n",
              "      <th>JSTUSDT_return</th>\n",
              "      <th>JSTUSDT_volatility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>91785.18</td>\n",
              "      <td>44.25582000</td>\n",
              "      <td>9784</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.057275</td>\n",
              "      <td>30532.801818</td>\n",
              "      <td>2522.98</td>\n",
              "      <td>1236.00450000</td>\n",
              "      <td>7010</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.164628</td>\n",
              "      <td>0.395882</td>\n",
              "      <td>0.03331</td>\n",
              "      <td>18269.00000000</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.030021</td>\n",
              "      <td>0.008186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>91837.75</td>\n",
              "      <td>29.64367000</td>\n",
              "      <td>7048</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.134171</td>\n",
              "      <td>30363.719702</td>\n",
              "      <td>2525.15</td>\n",
              "      <td>609.72690000</td>\n",
              "      <td>4877</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.117398</td>\n",
              "      <td>0.394875</td>\n",
              "      <td>0.03332</td>\n",
              "      <td>2854.40000000</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>91960.97</td>\n",
              "      <td>70.22032000</td>\n",
              "      <td>6386</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.106784</td>\n",
              "      <td>29798.433752</td>\n",
              "      <td>2529.97</td>\n",
              "      <td>672.80150000</td>\n",
              "      <td>3844</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.070356</td>\n",
              "      <td>0.391564</td>\n",
              "      <td>0.03332</td>\n",
              "      <td>89531.30000000</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.030012</td>\n",
              "      <td>0.007655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91862.77</td>\n",
              "      <td>50.83532000</td>\n",
              "      <td>4539</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.209748</td>\n",
              "      <td>29594.091863</td>\n",
              "      <td>2525.85</td>\n",
              "      <td>595.41120000</td>\n",
              "      <td>3903</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.328561</td>\n",
              "      <td>0.388680</td>\n",
              "      <td>0.03333</td>\n",
              "      <td>328.80000000</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.120012</td>\n",
              "      <td>0.007285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91670.09</td>\n",
              "      <td>62.93148000</td>\n",
              "      <td>11779</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.141704</td>\n",
              "      <td>29585.077527</td>\n",
              "      <td>2516.18</td>\n",
              "      <td>1280.56490000</td>\n",
              "      <td>9605</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.070638</td>\n",
              "      <td>0.388194</td>\n",
              "      <td>0.03329</td>\n",
              "      <td>18030.80000000</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.030039</td>\n",
              "      <td>0.007097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129596</th>\n",
              "      <td>109030.02</td>\n",
              "      <td>21.06713000</td>\n",
              "      <td>3921</td>\n",
              "      <td>0.258126</td>\n",
              "      <td>11548.993178</td>\n",
              "      <td>-0.005164</td>\n",
              "      <td>3644.397554</td>\n",
              "      <td>2552.77</td>\n",
              "      <td>225.37620000</td>\n",
              "      <td>1890</td>\n",
              "      <td>...</td>\n",
              "      <td>0.046639</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142062</td>\n",
              "      <td>0.03616</td>\n",
              "      <td>738.40000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.388673</td>\n",
              "      <td>0.006327</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129597</th>\n",
              "      <td>109024.39</td>\n",
              "      <td>5.10152000</td>\n",
              "      <td>1789</td>\n",
              "      <td>0.273262</td>\n",
              "      <td>12009.730552</td>\n",
              "      <td>-0.026086</td>\n",
              "      <td>5426.627618</td>\n",
              "      <td>2551.81</td>\n",
              "      <td>1078.91390000</td>\n",
              "      <td>2178</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.148774</td>\n",
              "      <td>0.03616</td>\n",
              "      <td>1093.20000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.416551</td>\n",
              "      <td>0.006199</td>\n",
              "      <td>0.027655</td>\n",
              "      <td>0.003812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129598</th>\n",
              "      <td>108995.95</td>\n",
              "      <td>7.48873000</td>\n",
              "      <td>769</td>\n",
              "      <td>0.367793</td>\n",
              "      <td>11563.053932</td>\n",
              "      <td>0.007560</td>\n",
              "      <td>6267.356571</td>\n",
              "      <td>2550.74</td>\n",
              "      <td>90.29550000</td>\n",
              "      <td>1032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.040678</td>\n",
              "      <td>0.122519</td>\n",
              "      <td>0.150848</td>\n",
              "      <td>0.03617</td>\n",
              "      <td>1733.20000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.472222</td>\n",
              "      <td>0.005998</td>\n",
              "      <td>0.027647</td>\n",
              "      <td>0.004163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129599</th>\n",
              "      <td>109004.19</td>\n",
              "      <td>6.56241000</td>\n",
              "      <td>1298</td>\n",
              "      <td>0.332862</td>\n",
              "      <td>11303.698905</td>\n",
              "      <td>-0.043980</td>\n",
              "      <td>6550.656289</td>\n",
              "      <td>2551.22</td>\n",
              "      <td>90.74810000</td>\n",
              "      <td>584</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039335</td>\n",
              "      <td>-0.220264</td>\n",
              "      <td>0.148169</td>\n",
              "      <td>0.03618</td>\n",
              "      <td>33108.70000000</td>\n",
              "      <td>15</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.005770</td>\n",
              "      <td>-0.055279</td>\n",
              "      <td>0.004326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129600</th>\n",
              "      <td>108956.25</td>\n",
              "      <td>12.92937000</td>\n",
              "      <td>2879</td>\n",
              "      <td>0.255552</td>\n",
              "      <td>10955.847402</td>\n",
              "      <td>0.013694</td>\n",
              "      <td>6816.196983</td>\n",
              "      <td>2550.59</td>\n",
              "      <td>403.34900000</td>\n",
              "      <td>2425</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034755</td>\n",
              "      <td>0.147167</td>\n",
              "      <td>0.148852</td>\n",
              "      <td>0.03616</td>\n",
              "      <td>3410.80000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.416551</td>\n",
              "      <td>0.005474</td>\n",
              "      <td>-0.027655</td>\n",
              "      <td>0.004457</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>129601 rows Ã— 70 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-510fd123-93ed-4020-af87-b3b16ec15bff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-510fd123-93ed-4020-af87-b3b16ec15bff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-510fd123-93ed-4020-af87-b3b16ec15bff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-033042c2-f339-41c7-84d6-d67191d638bf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-033042c2-f339-41c7-84d6-d67191d638bf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-033042c2-f339-41c7-84d6-d67191d638bf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        BTCUSDT_close BTCUSDT_volume  BTCUSDT_numberOfTrades  \\\n",
              "0            91785.18    44.25582000                    9784   \n",
              "1            91837.75    29.64367000                    7048   \n",
              "2            91960.97    70.22032000                    6386   \n",
              "3            91862.77    50.83532000                    4539   \n",
              "4            91670.09    62.93148000                   11779   \n",
              "...               ...            ...                     ...   \n",
              "129596      109030.02    21.06713000                    3921   \n",
              "129597      109024.39     5.10152000                    1789   \n",
              "129598      108995.95     7.48873000                     769   \n",
              "129599      109004.19     6.56241000                    1298   \n",
              "129600      108956.25    12.92937000                    2879   \n",
              "\n",
              "        BTCUSDT_prev_return  BTCUSDT_prev_volatility  BTCUSDT_return  \\\n",
              "0                       NaN                      NaN        0.057275   \n",
              "1                       NaN                      NaN        0.134171   \n",
              "2                       NaN                      NaN       -0.106784   \n",
              "3                       NaN                      NaN       -0.209748   \n",
              "4                       NaN                      NaN        0.141704   \n",
              "...                     ...                      ...             ...   \n",
              "129596             0.258126             11548.993178       -0.005164   \n",
              "129597             0.273262             12009.730552       -0.026086   \n",
              "129598             0.367793             11563.053932        0.007560   \n",
              "129599             0.332862             11303.698905       -0.043980   \n",
              "129600             0.255552             10955.847402        0.013694   \n",
              "\n",
              "        BTCUSDT_volatility  ETHUSDT_close ETHUSDT_volume  \\\n",
              "0             30532.801818        2522.98  1236.00450000   \n",
              "1             30363.719702        2525.15   609.72690000   \n",
              "2             29798.433752        2529.97   672.80150000   \n",
              "3             29594.091863        2525.85   595.41120000   \n",
              "4             29585.077527        2516.18  1280.56490000   \n",
              "...                    ...            ...            ...   \n",
              "129596         3644.397554        2552.77   225.37620000   \n",
              "129597         5426.627618        2551.81  1078.91390000   \n",
              "129598         6267.356571        2550.74    90.29550000   \n",
              "129599         6550.656289        2551.22    90.74810000   \n",
              "129600         6816.196983        2550.59   403.34900000   \n",
              "\n",
              "        ETHUSDT_numberOfTrades  ...  ARKUSDT_prev_volatility  ARKUSDT_return  \\\n",
              "0                         7010  ...                      NaN        0.164628   \n",
              "1                         4877  ...                      NaN        0.117398   \n",
              "2                         3844  ...                      NaN       -0.070356   \n",
              "3                         3903  ...                      NaN       -0.328561   \n",
              "4                         9605  ...                      NaN       -0.070638   \n",
              "...                        ...  ...                      ...             ...   \n",
              "129596                    1890  ...                 0.046639        0.000000   \n",
              "129597                    2178  ...                 0.045151        0.000000   \n",
              "129598                    1032  ...                 0.040678        0.122519   \n",
              "129599                     584  ...                 0.039335       -0.220264   \n",
              "129600                    2425  ...                 0.034755        0.147167   \n",
              "\n",
              "        ARKUSDT_volatility  JSTUSDT_close  JSTUSDT_volume  \\\n",
              "0                 0.395882        0.03331  18269.00000000   \n",
              "1                 0.394875        0.03332   2854.40000000   \n",
              "2                 0.391564        0.03332  89531.30000000   \n",
              "3                 0.388680        0.03333    328.80000000   \n",
              "4                 0.388194        0.03329  18030.80000000   \n",
              "...                    ...            ...             ...   \n",
              "129596            0.142062        0.03616    738.40000000   \n",
              "129597            0.148774        0.03616   1093.20000000   \n",
              "129598            0.150848        0.03617   1733.20000000   \n",
              "129599            0.148169        0.03618  33108.70000000   \n",
              "129600            0.148852        0.03616   3410.80000000   \n",
              "\n",
              "       JSTUSDT_numberOfTrades  JSTUSDT_prev_return  JSTUSDT_prev_volatility  \\\n",
              "0                          13                  NaN                      NaN   \n",
              "1                           4                  NaN                      NaN   \n",
              "2                           8                  NaN                      NaN   \n",
              "3                           1                  NaN                      NaN   \n",
              "4                          13                  NaN                      NaN   \n",
              "...                       ...                  ...                      ...   \n",
              "129596                      2             0.388673                 0.006327   \n",
              "129597                      3             0.416551                 0.006199   \n",
              "129598                      2             0.472222                 0.005998   \n",
              "129599                     15             0.500000                 0.005770   \n",
              "129600                      3             0.416551                 0.005474   \n",
              "\n",
              "        JSTUSDT_return  JSTUSDT_volatility  \n",
              "0             0.030021            0.008186  \n",
              "1             0.000000            0.007935  \n",
              "2             0.030012            0.007655  \n",
              "3            -0.120012            0.007285  \n",
              "4             0.030039            0.007097  \n",
              "...                ...                 ...  \n",
              "129596        0.000000            0.003212  \n",
              "129597        0.027655            0.003812  \n",
              "129598        0.027647            0.004163  \n",
              "129599       -0.055279            0.004326  \n",
              "129600       -0.027655            0.004457  \n",
              "\n",
              "[129601 rows x 70 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_all[selected_f_all]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbm4EfCfetGY"
      },
      "source": [
        "Normalizing Data Z-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oYBQteQlgw_C"
      },
      "outputs": [],
      "source": [
        "##Normalization\n",
        "\n",
        "for x in selected_f_all:\n",
        "  data_all[x] = data_all[x].fillna(0)\n",
        "  data_all[x] = data_all[x].astype(float)\n",
        "  data_all[x] = (data_all[x]-data_all[x].mean())/(data_all[x].std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sdOT5kTessQ"
      },
      "source": [
        "Create time index for TimseNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PWQs34gQ7njD"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "df_stamp = data_all[['time']].rename(columns={'time':'dateTime'})\n",
        "df_stamp['dateTime'] = pd.to_datetime(df_stamp['dateTime'])\n",
        "df_stamp['month'] = df_stamp.dateTime.apply(lambda row: row.month, 1)\n",
        "df_stamp['day'] = df_stamp.dateTime.apply(lambda row: row.day, 1)\n",
        "df_stamp['weekday'] = df_stamp.dateTime.apply(lambda row: row.weekday(), 1)\n",
        "df_stamp['hour'] = df_stamp.dateTime.apply(lambda row: row.hour, 1)\n",
        "df_stamp['minute'] = df_stamp.dateTime.apply(lambda row: row.minute, 1)\n",
        "data_stamp = df_stamp.drop(['dateTime'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gskia2Lre1nx"
      },
      "source": [
        "Dataset Class and Creating DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roHtsxJxkdcw",
        "outputId": "154bf895-48a3-4b2e-c10a-43bc2e5433f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['BTCUSDT_close',\n",
              " 'BTCUSDT_volume',\n",
              " 'BTCUSDT_numberOfTrades',\n",
              " 'BTCUSDT_prev_return',\n",
              " 'BTCUSDT_prev_volatility',\n",
              " 'ETHUSDT_close',\n",
              " 'ETHUSDT_volume',\n",
              " 'ETHUSDT_numberOfTrades',\n",
              " 'ETHUSDT_prev_return',\n",
              " 'ETHUSDT_prev_volatility',\n",
              " 'XRPUSDT_close',\n",
              " 'XRPUSDT_volume',\n",
              " 'XRPUSDT_numberOfTrades',\n",
              " 'XRPUSDT_prev_return',\n",
              " 'XRPUSDT_prev_volatility',\n",
              " 'TRXUSDT_close',\n",
              " 'TRXUSDT_volume',\n",
              " 'TRXUSDT_numberOfTrades',\n",
              " 'TRXUSDT_prev_return',\n",
              " 'TRXUSDT_prev_volatility',\n",
              " 'SEIUSDT_close',\n",
              " 'SEIUSDT_volume',\n",
              " 'SEIUSDT_numberOfTrades',\n",
              " 'SEIUSDT_prev_return',\n",
              " 'SEIUSDT_prev_volatility',\n",
              " 'HBARUSDT_close',\n",
              " 'HBARUSDT_volume',\n",
              " 'HBARUSDT_numberOfTrades',\n",
              " 'HBARUSDT_prev_return',\n",
              " 'HBARUSDT_prev_volatility',\n",
              " 'XLMUSDT_close',\n",
              " 'XLMUSDT_volume',\n",
              " 'XLMUSDT_numberOfTrades',\n",
              " 'XLMUSDT_prev_return',\n",
              " 'XLMUSDT_prev_volatility',\n",
              " 'TIAUSDT_close',\n",
              " 'TIAUSDT_volume',\n",
              " 'TIAUSDT_numberOfTrades',\n",
              " 'TIAUSDT_prev_return',\n",
              " 'TIAUSDT_prev_volatility',\n",
              " 'ARKUSDT_close',\n",
              " 'ARKUSDT_volume',\n",
              " 'ARKUSDT_numberOfTrades',\n",
              " 'ARKUSDT_prev_return',\n",
              " 'ARKUSDT_prev_volatility',\n",
              " 'JSTUSDT_close',\n",
              " 'JSTUSDT_volume',\n",
              " 'JSTUSDT_numberOfTrades',\n",
              " 'JSTUSDT_prev_return',\n",
              " 'JSTUSDT_prev_volatility']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_f_all = [x for x in selected_f_all if (('return' not in x) or ('prev_return' in x))]\n",
        "selected_f_all = [x for x in selected_f_all if (('volatility' not in x) or ('prev_volatility' in x))]\n",
        "selected_f_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Pfe2ODdGKlBd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class NewsTimeSeriesDataset(Dataset):\n",
        "    def __init__(self, df, data_stamp, selected_f_all, stock_list, seq_len=30):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.data_stamp = data_stamp.reset_index(drop=True)\n",
        "        self.features = selected_f_all\n",
        "        self.seq_len = seq_len\n",
        "        self.stock_list = [x+'_return' for x in stock_list]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df) - self.seq_len-shifted_window\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ts_window = self.df.loc[idx:idx + self.seq_len - 1, self.features].values.astype('float32')\n",
        "        # x_mask = self.data_stamp.loc[idx:idx + self.seq_len - 1].values.astype('float32')\n",
        "        news_window = self.df.loc[idx:idx + self.seq_len - 1, 'embedding'].values\n",
        "        news_window = np.stack(news_window).astype('float32')\n",
        "        target = self.df.loc[idx + self.seq_len:idx + self.seq_len+shifted_window-1, self.stock_list].values.astype('float32')  # shape: [19]\n",
        "        return {\n",
        "            'timeseries': torch.tensor(ts_window),     # [30, 114]\n",
        "            'news': torch.tensor(news_window),         # [30, 768]\n",
        "            'target': torch.tensor(target)\n",
        "            # 'time_mask':torch.tensor(x_mask)# [19]\n",
        "        }\n",
        "\n",
        "\n",
        "split = int(0.8 * len(data_all))\n",
        "\n",
        "data_train = data_all[data_all['day']<'2025-05-10'].copy()\n",
        "data_test = data_all[data_all['day']>='2025-05-10'].copy()\n",
        "train_dataset = NewsTimeSeriesDataset(data_train, data_stamp.iloc[:split], selected_f_all, list_crypto, seq_len=shifted_window)\n",
        "val_dataset = NewsTimeSeriesDataset(data_test, data_stamp.iloc[split:], selected_f_all, list_crypto, seq_len=shifted_window)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8TYjqaHTsshM"
      },
      "outputs": [],
      "source": [
        "def func_loss(output, target, top_k=7):# Step 1: Normalize weights\n",
        "  weights = torch.tanh(output)\n",
        "  weights = weights / (torch.sum(torch.abs(weights), dim=1, keepdim=True) + 1e-8)\n",
        "\n",
        "  # Step 2: Compute portfolio return sequence\n",
        "  weights_exp = weights.unsqueeze(1)  # [B, 1, N]\n",
        "  # print((weights_exp * target).shape)\n",
        "  portfolio_returns = torch.sum(weights_exp * target, dim=2)  # [B, T]\n",
        "\n",
        "  # Step 3: Sharpe ratio\n",
        "  mean_r = torch.mean(portfolio_returns, dim=1)\n",
        "  std_r = torch.std(portfolio_returns, dim=1) + 1e-6\n",
        "  sharpe = mean_r / std_r\n",
        "  loss_sharpe = -torch.mean(sharpe)\n",
        "\n",
        "  # Step 4: Diversification penalty\n",
        "  loss_diversify = torch.mean(weights ** 2)  # Encourage distributed weights\n",
        "\n",
        "  # Step 5: Total loss\n",
        "  Î»_div = 0.01\n",
        "  loss = loss_sharpe + Î»_div * loss_diversify\n",
        "  return loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoqSg9XZD11W"
      },
      "source": [
        "Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "avriBN1s5zrP"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=500):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)  # [max_len, d_model]\n",
        "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)  # [max_len, 1]\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))  # [d_model/2]\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)  # even dims\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)  # odd dims\n",
        "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_len, d_model]\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return x\n",
        "\n",
        "class TransformerReturnPredictor(nn.Module):\n",
        "    def __init__(self, feature_dim, d_model=64, nhead=4, num_layers=2, max_len=500):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(feature_dim, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_len=max_len)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.output_layer = nn.Linear(d_model, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_len, feature_dim]\n",
        "        x = self.input_proj(x)             # [batch_size, seq_len, d_model]\n",
        "        x = self.pos_encoder(x)            # Add positional encoding\n",
        "        x = self.transformer(x)            # [batch_size, seq_len, d_model]\n",
        "        x = x[:, -1, :]                    # Use representation of last time step\n",
        "        return self.output_layer(x).squeeze(-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "suadoQon5Wu8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.fft\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "finbert_model_name = \"yiyanghkust/finbert-tone\"\n",
        "import torch.nn as nn\n",
        "\n",
        "class MarketNewsFusionModel(nn.Module):\n",
        "    def __init__(self, ts_input_dim, news_embed_dim, hidden_dim=64, num_stocks=19,\n",
        "                 max_len=30, d_model=64, nhead=4, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.num_stocks = num_stocks\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.input_proj = nn.Linear(ts_input_dim, self.d_model)\n",
        "        self.pos_encoder = PositionalEncoding(self.d_model, max_len=max_len)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.d_model, nhead=nhead, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.ts_out = nn.Linear(128, hidden_dim)\n",
        "\n",
        "        # 2. News LSTM\n",
        "        self.news_proj = nn.Linear(news_embed_dim, 64)\n",
        "        self.news_lstm = nn.LSTM(input_size=64, hidden_size=hidden_dim, batch_first=True)\n",
        "\n",
        "        # 3. Stock-specific regression heads (1 per stock)\n",
        "        self.stock_heads = nn.Sequential(\n",
        "                nn.Linear(self.d_model+hidden_dim, 64),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(64, num_stocks)\n",
        "            )\n",
        "\n",
        "    def forward(self, ts_input, x_mark_enc, news_input):  # [B, 30, F], [B, 30, E]\n",
        "\n",
        "                # Transformer on OHLCV\n",
        "        x = self.input_proj(ts_input)           # [B, T, d_model]\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.transformer(x)                  # [B, T, d_model]\n",
        "        ts_emb = x[:, -1, :].squeeze(1)                   # [B, d_model]\n",
        "\n",
        "\n",
        "        news_proj = self.news_proj(news_input)         # [B, 30, 64]\n",
        "        _, (hn, _) = self.news_lstm(news_proj)        # hn: [1, B, 64]\n",
        "        news_emb = hn[-1]                              # [B, 64]\n",
        "\n",
        "        fused = torch.cat([ts_emb, news_emb], dim=1)   # [B, 128]\n",
        "\n",
        "        outputs = self.stock_heads(fused).squeeze(-1)\n",
        "        return outputs             # [B, 19]\n",
        "\n",
        "\n",
        "seq_len = shifted_window\n",
        "\n",
        "# model = TimesNet.Model(args).float()\n",
        "# model = Model_TimesNet(configs).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EqIKS4Cz_eaG"
      },
      "outputs": [],
      "source": [
        "data_all = data_all.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRmvz0Zd05DW",
        "outputId": "ef4728a0-ed02-47fa-da9f-4a622bd8d8ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seq_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izF1C6gMEdON"
      },
      "source": [
        "Loading Model and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dcq4GZM8gcgn"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Example setup\n",
        "# selected_f_all = list of feature columns (e.g., 6 Ã— 19 = 114)\n",
        "# stock_list = ['AAPL', 'GOOG', ..., 'TSLA'] â†’ 19 stock target columns\n",
        "# df = your dataframe with those columns and 'embedding' column\n",
        "\n",
        "\n",
        "split = int(0.8 * len(data_all))\n",
        "\n",
        "# train_dataset = NewsTimeSeriesDataset(data_all.iloc[:split], data_stamp.iloc[:split], selected_f_all, list_crypto, seq_len=30)\n",
        "# val_dataset = NewsTimeSeriesDataset(data_all.iloc[split:], data_stamp.iloc[split:], selected_f_all, list_crypto, seq_len=30)\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "data_train = data_all[data_all['day']<'2025-05-10'].copy()\n",
        "data_test = data_all[data_all['day']>='2025-05-10'].copy()\n",
        "train_dataset = NewsTimeSeriesDataset(data_train, data_stamp.iloc[:split], selected_f_all, list_crypto, seq_len=shifted_window)\n",
        "val_dataset = NewsTimeSeriesDataset(data_test, data_stamp.iloc[split:], selected_f_all, list_crypto, seq_len=shifted_window)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "model = MarketNewsFusionModel(ts_input_dim=len(selected_f_all),\n",
        " news_embed_dim=len(data_all['embedding'].iloc[0]),\n",
        " hidden_dim=64,\n",
        " num_stocks=len(list_crypto),\n",
        " max_len=shifted_window,\n",
        " d_model=64, nhead=4, num_layers=2).cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9ZdJH7BEiAc"
      },
      "source": [
        "Testing model pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "sk_4Oo6zhmTf"
      },
      "outputs": [],
      "source": [
        "# One training step\n",
        "for batch in val_loader:\n",
        "    ts_input = batch['timeseries'].cuda()\n",
        "    news_input = batch['news'].cuda()\n",
        "    target = batch['target'].cuda()\n",
        "    # time_mask = batch['time_mask'].cuda()\n",
        "    time_mask = 1\n",
        "    output = model(ts_input, time_mask, news_input)  # [B, 19]\n",
        "    loss = func_loss(output, target)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVdn_Cq9Ek9W"
      },
      "source": [
        "Validation Function and Portfolio Creator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx6_X43CvAm9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def func_validation(output, target, top_k=7):# Step 1: Normalize weights\n",
        "  weights = torch.tanh(output)\n",
        "  weights = weights / (torch.sum(torch.abs(weights), dim=1, keepdim=True) + 1e-8)\n",
        "\n",
        "  # Step 2: Compute portfolio return sequence\n",
        "  weights_exp = weights.unsqueeze(1)  # [B, 1, N]\n",
        "  # print((weights_exp * target).shape)\n",
        "  portfolio_returns = torch.sum(weights_exp * target, dim=2)  # [B, T]\n",
        "\n",
        "  # Step 3: Sharpe ratio\n",
        "  mean_r = torch.mean(portfolio_returns, dim=1)\n",
        "  std_r = torch.std(portfolio_returns, dim=1) + 1e-6\n",
        "  sharpe = mean_r / std_r\n",
        "  return mean_r, sharpe\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def func_generate_portfolio(all_preds):\n",
        "\n",
        "  only_top_k = True\n",
        "  # len(self.df) - self.seq_len-shifted_window\n",
        "  predicted_array = np.vstack(all_preds)\n",
        "\n",
        "  df_weight_pred = data_test[shifted_window:-shifted_window][['dateTime']+[x+'_return' for x in list_crypto]].copy()\n",
        "\n",
        "  df_return = data_test[shifted_window:-shifted_window][['dateTime']+[x+'_return' for x in list_crypto]].copy()\n",
        "  list_weight = []\n",
        "  for i in range(len(list_crypto)):\n",
        "    df_weight_pred[list_crypto[i]+'_weight'] = predicted_array[:,i]\n",
        "    list_weight.append(list_crypto[i]+'_weight')\n",
        "\n",
        "  sum_weight = abs(df_weight_pred[list_weight]).sum(axis=1).copy()\n",
        "  for x in list_weight:\n",
        "    df_weight_pred[x] = df_weight_pred[x]/sum_weight\n",
        "\n",
        "  df_weight_pred.to_pickle('/content/drive/MyDrive/Portfolio/20of20_30min_stock_df_weight_pred_epoch{}.pickle'.format(str(epoch)))\n",
        "\n",
        "  df_weight_30 = df_weight_pred[['dateTime']+list(df_weight_pred.columns[-len(list_weight):])].iloc[::shifted_window].reset_index().drop('index',axis=1)\n",
        "  df_portfolio = df_return.merge(df_weight_30, on='dateTime', how='left')\n",
        "  df_portfolio = df_portfolio.fillna(method='ffill')\n",
        "  list_portfolio = []\n",
        "  for x in list_crypto:\n",
        "    df_portfolio[x+'_value'] = df_portfolio[x+'_weight']*df_portfolio[x+'_return']\n",
        "    list_portfolio.append(x+'_value')\n",
        "  df_portfolio['portfolio'] = df_portfolio[list_portfolio].cumsum().sum(axis=1)\n",
        "  df_portfolio.to_pickle('/content/drive/MyDrive/Portfolio/20of20_30min_stock_df_portfolio_epoch{}.pickle'.format(str(epoch)))\n",
        "\n",
        "  # Example: Plot df['y'] vs df['x']\n",
        "  plt.figure(figsize=(10, 5))  # Optional: adjust figure size\n",
        "\n",
        "  plt.plot(df_portfolio['dateTime'], df_portfolio['portfolio'])  # You can remove `marker` if not needed\n",
        "\n",
        "  # Add grid\n",
        "  plt.grid(True)\n",
        "\n",
        "  # Rotate x-axis labels\n",
        "  plt.xticks(rotation=45)\n",
        "\n",
        "  # Optional: Add labels and title\n",
        "  plt.xlabel('X-axis')\n",
        "  plt.ylabel('Y-axis')\n",
        "  plt.title('portfolio cum return')\n",
        "\n",
        "  plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
        "  plt.savefig('/content/drive/MyDrive/Portfolio/20of20_30min_stock_df_portfolio_epoch{}.png'.format(str(epoch)), dpi=300)  # or .jpg, .svg, .pdf\n",
        "\n",
        "  plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "iYBzmKXExo2C"
      },
      "outputs": [],
      "source": [
        "# One training step\n",
        "for batch in train_loader:\n",
        "    ts_input = batch['timeseries'].cuda()\n",
        "    news_input = batch['news'].cuda()\n",
        "    target = batch['target'].cuda()\n",
        "    # time_mask = batch['time_mask'].cuda()\n",
        "    time_mask = 1\n",
        "    output = model(ts_input, time_mask, news_input)  # [B, 19]\n",
        "    loss = func_loss(output, target)\n",
        "    mean_r, sharp = func_validation(output, target)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HYSvx1aYglIR",
        "outputId": "86bc10de-0dee-4b36-e380-9b8e524d2a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ” Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 1/3329 [00:00<40:09,  1.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 0/3329 - Batch Loss: -0.0330 - Avg Loss: -0.0330\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   3%|â–Ž         | 101/3329 [00:54<28:42,  1.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 100/3329 - Batch Loss: 0.0098 - Avg Loss: -0.0073\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   6%|â–Œ         | 201/3329 [01:48<28:00,  1.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 200/3329 - Batch Loss: -0.0263 - Avg Loss: -0.0065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   9%|â–‰         | 301/3329 [02:41<26:59,  1.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 300/3329 - Batch Loss: 0.0024 - Avg Loss: -0.0105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  12%|â–ˆâ–        | 401/3329 [03:35<26:22,  1.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 400/3329 - Batch Loss: -0.0459 - Avg Loss: -0.0131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  15%|â–ˆâ–Œ        | 501/3329 [04:28<25:02,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 500/3329 - Batch Loss: -0.0425 - Avg Loss: -0.0142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  18%|â–ˆâ–Š        | 601/3329 [05:22<24:14,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 600/3329 - Batch Loss: -0.1037 - Avg Loss: -0.0157\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  21%|â–ˆâ–ˆ        | 701/3329 [06:16<23:26,  1.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 700/3329 - Batch Loss: 0.0157 - Avg Loss: -0.0162\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  24%|â–ˆâ–ˆâ–       | 801/3329 [07:10<22:25,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 800/3329 - Batch Loss: 0.0038 - Avg Loss: -0.0165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  27%|â–ˆâ–ˆâ–‹       | 901/3329 [08:03<21:56,  1.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 900/3329 - Batch Loss: -0.0658 - Avg Loss: -0.0176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  30%|â–ˆâ–ˆâ–ˆ       | 1001/3329 [08:57<20:49,  1.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1000/3329 - Batch Loss: -0.0324 - Avg Loss: -0.0193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1101/3329 [09:50<19:58,  1.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1100/3329 - Batch Loss: -0.0372 - Avg Loss: -0.0206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1201/3329 [10:44<18:43,  1.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1200/3329 - Batch Loss: -0.0295 - Avg Loss: -0.0215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1301/3329 [11:37<18:00,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1300/3329 - Batch Loss: -0.0975 - Avg Loss: -0.0228\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1401/3329 [12:31<17:16,  1.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1400/3329 - Batch Loss: -0.0715 - Avg Loss: -0.0237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1501/3329 [13:24<16:17,  1.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1500/3329 - Batch Loss: -0.0432 - Avg Loss: -0.0248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1601/3329 [14:17<15:32,  1.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1600/3329 - Batch Loss: -0.0435 - Avg Loss: -0.0259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1701/3329 [15:11<14:22,  1.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1700/3329 - Batch Loss: 0.0082 - Avg Loss: -0.0269\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1801/3329 [16:04<13:30,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1800/3329 - Batch Loss: -0.0330 - Avg Loss: -0.0275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1901/3329 [16:57<12:35,  1.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1900/3329 - Batch Loss: -0.0545 - Avg Loss: -0.0285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2001/3329 [17:51<11:55,  1.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2000/3329 - Batch Loss: 0.0206 - Avg Loss: -0.0293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2101/3329 [18:44<10:54,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2100/3329 - Batch Loss: -0.0759 - Avg Loss: -0.0306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2201/3329 [19:37<10:12,  1.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2200/3329 - Batch Loss: -0.0265 - Avg Loss: -0.0312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2301/3329 [20:31<09:07,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2300/3329 - Batch Loss: -0.0408 - Avg Loss: -0.0317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2401/3329 [21:24<08:17,  1.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2400/3329 - Batch Loss: -0.0154 - Avg Loss: -0.0326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2501/3329 [22:17<07:19,  1.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2500/3329 - Batch Loss: -0.0499 - Avg Loss: -0.0335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2601/3329 [23:11<06:28,  1.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2600/3329 - Batch Loss: -0.0555 - Avg Loss: -0.0342\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2701/3329 [24:04<05:34,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2700/3329 - Batch Loss: -0.0499 - Avg Loss: -0.0352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2801/3329 [24:58<04:44,  1.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2800/3329 - Batch Loss: 0.0077 - Avg Loss: -0.0360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2901/3329 [25:51<03:49,  1.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2900/3329 - Batch Loss: -0.1139 - Avg Loss: -0.0367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3001/3329 [26:45<02:55,  1.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 3000/3329 - Batch Loss: -0.0567 - Avg Loss: -0.0376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3101/3329 [27:39<02:01,  1.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 3100/3329 - Batch Loss: -0.1081 - Avg Loss: -0.0383\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3201/3329 [28:32<01:07,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 3200/3329 - Batch Loss: -0.0863 - Avg Loss: -0.0392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3301/3329 [29:26<00:15,  1.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 3300/3329 - Batch Loss: -0.0910 - Avg Loss: -0.0399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3329/3329 [29:41<00:00,  1.87it/s]\n",
            "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 719/719 [01:30<00:00,  7.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Epoch 1 Summary:\n",
            "  Train Loss: -0.0401\n",
            "  Val Loss: -0.0117\n",
            "Mean Return  89.4512 0.050729796 0.6182812 -0.39088786\n",
            "Sharpe  0.012911342 0.16645724 0.78109246 -0.7461602\n",
            "Winrate 0.5291762760541316\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Best model saved.\n",
            "\n",
            "ðŸ” Epoch 2/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 1/3329 [00:00<31:26,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 0/3329 - Batch Loss: -0.1105 - Avg Loss: -0.1105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   3%|â–Ž         | 101/3329 [00:56<30:23,  1.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 100/3329 - Batch Loss: -0.0259 - Avg Loss: -0.0654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   6%|â–Œ         | 201/3329 [01:53<29:24,  1.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 200/3329 - Batch Loss: -0.0881 - Avg Loss: -0.0675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   9%|â–‰         | 301/3329 [02:49<28:30,  1.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 300/3329 - Batch Loss: -0.0256 - Avg Loss: -0.0665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  12%|â–ˆâ–        | 401/3329 [03:46<27:40,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 400/3329 - Batch Loss: -0.0398 - Avg Loss: -0.0676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  15%|â–ˆâ–Œ        | 501/3329 [04:43<26:39,  1.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 500/3329 - Batch Loss: -0.0599 - Avg Loss: -0.0691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  18%|â–ˆâ–Š        | 601/3329 [05:39<25:45,  1.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 600/3329 - Batch Loss: -0.0737 - Avg Loss: -0.0699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  21%|â–ˆâ–ˆ        | 701/3329 [06:36<24:52,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 700/3329 - Batch Loss: -0.0632 - Avg Loss: -0.0712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  24%|â–ˆâ–ˆâ–       | 801/3329 [07:33<23:49,  1.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 800/3329 - Batch Loss: -0.0428 - Avg Loss: -0.0719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  27%|â–ˆâ–ˆâ–‹       | 901/3329 [08:29<22:52,  1.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 900/3329 - Batch Loss: -0.0770 - Avg Loss: -0.0725\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  30%|â–ˆâ–ˆâ–ˆ       | 1001/3329 [09:26<21:59,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1000/3329 - Batch Loss: -0.0757 - Avg Loss: -0.0730\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1101/3329 [10:22<21:00,  1.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1100/3329 - Batch Loss: -0.0953 - Avg Loss: -0.0736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1201/3329 [11:19<19:55,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1200/3329 - Batch Loss: -0.0596 - Avg Loss: -0.0741\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1301/3329 [12:15<19:01,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1300/3329 - Batch Loss: -0.1125 - Avg Loss: -0.0748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1401/3329 [13:12<18:20,  1.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1400/3329 - Batch Loss: -0.0957 - Avg Loss: -0.0754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1501/3329 [14:08<17:12,  1.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1500/3329 - Batch Loss: -0.0420 - Avg Loss: -0.0757\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1601/3329 [15:05<16:12,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1600/3329 - Batch Loss: -0.1105 - Avg Loss: -0.0765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1701/3329 [16:01<15:27,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1700/3329 - Batch Loss: -0.1420 - Avg Loss: -0.0772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1801/3329 [16:58<14:12,  1.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1800/3329 - Batch Loss: -0.1238 - Avg Loss: -0.0778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1901/3329 [17:54<13:39,  1.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 1900/3329 - Batch Loss: -0.0400 - Avg Loss: -0.0780\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2001/3329 [18:51<12:27,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2000/3329 - Batch Loss: -0.0573 - Avg Loss: -0.0785\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2101/3329 [19:47<11:29,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2100/3329 - Batch Loss: -0.1066 - Avg Loss: -0.0791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2201/3329 [20:43<10:45,  1.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2200/3329 - Batch Loss: -0.0724 - Avg Loss: -0.0797\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2301/3329 [21:39<09:34,  1.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2300/3329 - Batch Loss: -0.1127 - Avg Loss: -0.0802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2401/3329 [22:36<08:46,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2400/3329 - Batch Loss: -0.1159 - Avg Loss: -0.0809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2501/3329 [23:32<07:45,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2500/3329 - Batch Loss: -0.1007 - Avg Loss: -0.0814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2601/3329 [24:29<06:50,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2600/3329 - Batch Loss: -0.0176 - Avg Loss: -0.0819\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2701/3329 [25:25<05:51,  1.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2700/3329 - Batch Loss: -0.0693 - Avg Loss: -0.0824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2801/3329 [26:21<04:56,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2800/3329 - Batch Loss: -0.1194 - Avg Loss: -0.0831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2901/3329 [27:18<04:02,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Step 2900/3329 - Batch Loss: -0.1235 - Avg Loss: -0.0837\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2983/3329 [28:05<03:16,  1.76it/s]"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def compute_r2_per_stock(y_true, y_pred):\n",
        "    r2s = []\n",
        "    for i in range(y_true.shape[1]):\n",
        "        r2s.append(r2_score(y_true[:, i], y_pred[:, i]))\n",
        "    return r2s\n",
        "\n",
        "num_epochs=50\n",
        "patience=5\n",
        "save_path='/content/drive/MyDrive/Portfolio/best_model_20of20_v2_30min.pth'\n",
        "device='cuda'\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "model = MarketNewsFusionModel(ts_input_dim=len(selected_f_all),\n",
        " news_embed_dim=len(data_all['embedding'].iloc[0]),\n",
        " hidden_dim=64,\n",
        " num_stocks=len(list_crypto),\n",
        " max_len=shifted_window,\n",
        " d_model=64, nhead=4, num_layers=2).cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "\n",
        "    print(f\"\\nðŸ” Epoch {epoch}/{num_epochs}\")\n",
        "    for step, batch in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        ts_input = batch['timeseries'].to(device)\n",
        "        news_input = batch['news'].to(device)\n",
        "        target = batch['target'].to(device)\n",
        "        time_mask = 1 #batch['time_mask'].to(device)\n",
        "\n",
        "        output = model(ts_input, time_mask, news_input)\n",
        "        loss = func_loss(output, target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Step-wise print every 100 steps\n",
        "        if step % 100 == 0:\n",
        "            avg_loss = total_train_loss / (step + 1)\n",
        "            print(f\"  Step {step}/{len(train_loader)} - Batch Loss: {loss.item():.4f} - Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    all_preds, all_targets = [], []\n",
        "    all_return, all_sharp = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
        "            ts_input = batch['timeseries'].to(device)\n",
        "            news_input = batch['news'].to(device)\n",
        "            target = batch['target'].to(device)\n",
        "            time_mask = 1 #batch['time_mask'].to(device)\n",
        "\n",
        "            output = model(ts_input, time_mask, news_input)\n",
        "            loss = func_loss(output, target)\n",
        "            mean_r, sharp = func_validation(output, target)\n",
        "            total_val_loss += loss.item()\n",
        "            output = torch.tanh(output)\n",
        "            all_preds.append(output.cpu().numpy())\n",
        "            all_targets.append(target.cpu().numpy())\n",
        "            all_return.extend(mean_r.cpu().numpy())\n",
        "            all_sharp.extend(sharp.cpu().numpy())\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "    # y_pred = np.concatenate(all_preds, axis=0)\n",
        "    # y_true = np.concatenate(all_targets, axis=0)\n",
        "    # r2_scores = compute_r2_per_stock(y_true, y_pred)\n",
        "\n",
        "    print(f\"ðŸ“Š Epoch {epoch} Summary:\")\n",
        "    print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"  Val Loss: {avg_val_loss:.4f}\")\n",
        "    print(\"Mean Return \", np.sum(all_return), np.std(all_return), np.max(all_return), np.min(all_return))\n",
        "    print(\"Sharpe \", np.mean(all_sharp), np.std(all_sharp), np.max(all_sharp), np.min(all_sharp))\n",
        "    print('Winrate', sum([1 for x in all_return if x>0])/len(all_return))\n",
        "    # print(\"  RÂ² per stock:\", [\"{} , {:.3f}\".format(list_crypto_first[r], r2_scores[r]) for r in range(len(r2_scores))])\n",
        "\n",
        "    func_generate_portfolio(all_preds)\n",
        "    # if epoch % 5 == 0:\n",
        "    #     np.save(f\"y_pred_epoch_{epoch}.npy\", y_pred)\n",
        "    #     np.save(f\"y_true_epoch_{epoch}.npy\", y_true)\n",
        "\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(\"âœ… Best model saved.\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"â³ Early stopping patience: {patience_counter}/{patience}\")\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(\"â›” Early stopping triggered.\")\n",
        "        break\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
