{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bqamciNPoHw",
        "outputId": "ef276059-afd2-4373-be35-3521e99cdfde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/TimesNet\n",
            "ohlcv_BINANCE_ETHUSDT.P.csv  TimesNet.ipynb\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/TimesNet/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CALRMFu5QMza"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrXN0ZxjQrNd"
      },
      "outputs": [],
      "source": [
        "class InceptionBlock2D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.branch1 = nn.Conv2d(in_channels, out_channels, kernel_size=(1, 7), padding=(0, 3))  # Extended time horizon for short-term patterns\n",
        "        self.branch2 = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 5), padding=(1, 2))  # Balanced time-feature relationships\n",
        "        self.branch3 = nn.Conv2d(in_channels, out_channels, kernel_size=(7, 3), padding=(3, 1))  # Enhanced cross-feature interactions\n",
        "        self.relu = nn.ReLU()\n",
        "        self.bn = nn.BatchNorm2d(out_channels * 3)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.branch1(x)\n",
        "        out2 = self.branch2(x)\n",
        "        out3 = self.branch3(x)\n",
        "        out = torch.cat([out1, out2, out3], dim=1)\n",
        "        out = self.relu(self.bn(out))\n",
        "        return self.dropout(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKxx1y28STOa"
      },
      "outputs": [],
      "source": [
        "class TimesBlock(nn.Module):\n",
        "    def __init__(self, d_model, top_k=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.top_k = top_k\n",
        "        self.d_model = d_model\n",
        "        self.inception = InceptionBlock2D(1, 1, dropout)\n",
        "        self.output_proj = nn.Linear(3, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, T = x.shape\n",
        "        freq = torch.fft.rfft(x, dim=-1)\n",
        "        amplitude = freq.abs()[:, :, 1:]\n",
        "        topk_indices = torch.topk(amplitude, self.top_k, dim=-1)[1]\n",
        "        periods = (T // (topk_indices + 1)).clamp(min=2)\n",
        "        output = torch.zeros_like(x)\n",
        "\n",
        "        for k in range(self.top_k):\n",
        "            p = periods[:, :, k]\n",
        "            median_p = int(torch.median(p).item())\n",
        "            seq_len = (T // median_p) * median_p\n",
        "            views = x[:, :, :seq_len].reshape(B, C, -1, median_p)\n",
        "            views = views.view(B * C, 1, views.shape[2], median_p)\n",
        "            conv_out = self.inception(views)\n",
        "            conv_out = conv_out.mean(dim=[2, 3])\n",
        "            conv_out = conv_out.view(B, C, -1)\n",
        "            proj_out = self.output_proj(conv_out)\n",
        "            output += proj_out\n",
        "\n",
        "        return self.dropout(output / self.top_k) + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tcizx88FW71_"
      },
      "outputs": [],
      "source": [
        "class TimesNet(nn.Module):\n",
        "    def __init__(self, d_model=64, num_blocks=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.ModuleList([TimesBlock(d_model, dropout=dropout) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nmm51zn5W-B9"
      },
      "outputs": [],
      "source": [
        "class TimesNetForecaster(nn.Module):\n",
        "    def __init__(self, input_channels, seq_len, pred_len, d_model=128, num_blocks=4, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.feature_embedding = nn.Sequential(\n",
        "            nn.Linear(input_channels, d_model),\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.input_proj = nn.Sequential(\n",
        "            nn.Linear(seq_len, d_model),\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.backbone = TimesNet(d_model=d_model, num_blocks=num_blocks, dropout=dropout)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model * 2),\n",
        "            nn.LayerNorm(d_model * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model * 2, d_model),\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model, pred_len)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_embedding(x)   # [B, T, d_model]\n",
        "        x = x.transpose(1, 2)           # [B, d_model, T]\n",
        "        x = self.input_proj(x)          # [B, d_model, d_model]\n",
        "        x = self.backbone(x)\n",
        "        x = x.transpose(1, 2)           # [B, d_model, d_model]\n",
        "        return self.head(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eio_8a_XdyS"
      },
      "outputs": [],
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, data, seq_len, pred_len, target_column=-1, stride=30):\n",
        "        self.input_data = torch.tensor(data[:, :-1], dtype=torch.float32)\n",
        "        self.target_data = torch.tensor(data[:, target_column], dtype=torch.float32)\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len = pred_len\n",
        "        self.indices = list(range(0, len(data) - seq_len - pred_len + 1, stride))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        i = self.indices[idx]\n",
        "        x = self.input_data[i:i+self.seq_len]\n",
        "        y = self.target_data[i+self.seq_len:i+self.seq_len+self.pred_len]\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGssHCDZJRA0"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_data, val_data, seq_len, pred_len, batch_size=64, epochs=5, lr=1e-3, stride=30, target_col=-1):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    train_loader = DataLoader(TimeSeriesDataset(train_data, seq_len, pred_len, target_col, stride), batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(TimeSeriesDataset(val_data, seq_len, pred_len, target_col, stride), batch_size=batch_size)\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
        "        for X, y in pbar:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X).mean(dim=1)\n",
        "            loss = criterion(pred, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            pbar.set_postfix(loss=loss.item())\n",
        "\n",
        "        trues, preds = [], []\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X, y in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                pred = model(X).mean(dim=1)\n",
        "                val_loss += criterion(pred, y).item()\n",
        "                preds.append(pred.cpu().numpy())\n",
        "                trues.append(y.cpu().numpy())\n",
        "\n",
        "        preds = np.concatenate(preds)\n",
        "        trues = np.concatenate(trues)\n",
        "        r2 = r2_score(trues, preds)\n",
        "        print(f\"Epoch {epoch+1}, Val Loss: {val_loss / len(val_loader):.4f}, R2: {r2:.4f}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkTtQZ_YJUgE"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_data, seq_len, pred_len, batch_size=128, stride=30, target_col=-1):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    dataset = TimeSeriesDataset(test_data, seq_len, pred_len, target_col, stride)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "    preds, trues = [], []\n",
        "    with torch.no_grad():\n",
        "        for X, y in loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            out = model(X).mean(dim=1)\n",
        "            preds.append(out.cpu().numpy())\n",
        "            trues.append(y.cpu().numpy())\n",
        "\n",
        "    preds = np.concatenate(preds)\n",
        "    trues = np.concatenate(trues)\n",
        "\n",
        "    mse = mean_squared_error(trues, preds)\n",
        "    mae = mean_absolute_error(trues, preds)\n",
        "    r2 = r2_score(trues, preds)\n",
        "    print(f\"Test MSE: {mse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT4APcILm1G5"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"ohlcv_BINANCE_ETHUSDT.P.csv\")\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "df['minute']     = df['timestamp'].dt.minute\n",
        "df['hour']       = df['timestamp'].dt.hour\n",
        "df['day']        = df['timestamp'].dt.day\n",
        "df['dayofweek']  = df['timestamp'].dt.dayofweek\n",
        "df['month']      = df['timestamp'].dt.month\n",
        "\n",
        "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "\n",
        "df['minute_sin'] = np.sin(2 * np.pi * df['minute'] / 60)\n",
        "df['minute_cos'] = np.cos(2 * np.pi * df['minute'] / 60)\n",
        "\n",
        "df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
        "df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oJOXTSobBRj",
        "outputId": "1043143f-e032-420b-a5ee-3c209b355987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['symbol', 'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
            "       'minute', 'hour', 'day', 'dayofweek', 'month', 'hour_sin', 'hour_cos',\n",
            "       'minute_sin', 'minute_cos', 'dayofweek_sin', 'dayofweek_cos'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "AYxPK8ViJXdd",
        "outputId": "6fe6854b-752e-40ca-a259-c161fc46b9a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "TimesNetForecaster model\n",
            "Training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5 [Train]:   4%|▍         | 21/473 [00:02<00:52,  8.65it/s, loss=1.62]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-7afa6529828a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     model = train_model(\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-f7c2f04773e0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, val_data, seq_len, pred_len, batch_size, epochs, lr, stride, target_col)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtrues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Loading data...\")\n",
        "    features = [\n",
        "        'open', 'high', 'low', 'close', 'volume',\n",
        "       'minute', 'hour', 'day', 'dayofweek', 'month', 'hour_sin', 'hour_cos',\n",
        "       'minute_sin', 'minute_cos', 'dayofweek_sin', 'dayofweek_cos'\n",
        "    ]\n",
        "\n",
        "    input_data = df[features].values\n",
        "    scaler = StandardScaler()\n",
        "    input_data = scaler.fit_transform(input_data)\n",
        "\n",
        "    df['pre_return'] = (1000 * df['close'].pct_change()).fillna(0)\n",
        "    pre_return_col = df['pre_return'].values.reshape(-1, 1)\n",
        "    input_data = np.hstack((input_data, pre_return_col))\n",
        "    target_data = df['pre_return']\n",
        "\n",
        "\n",
        "    data = np.column_stack([input_data, target_data])\n",
        "\n",
        "    train_size = int(len(data) * 0.7)\n",
        "    val_size = int(len(data) * 0.15)\n",
        "    train_data = data[:train_size]\n",
        "    val_data = data[train_size:train_size+val_size]\n",
        "    test_data = data[train_size+val_size:]\n",
        "\n",
        "    print(\"TimesNetForecaster model\")\n",
        "\n",
        "    model = TimesNetForecaster(\n",
        "        input_channels=len(features) + 1,\n",
        "        seq_len=360,\n",
        "        pred_len=60,\n",
        "        d_model=128,      # increased from 64\n",
        "        num_blocks=4,     # increased from 3\n",
        "        dropout=0.2       # increased from 0.1\n",
        "    )\n",
        "\n",
        "    print(\"Training model...\")\n",
        "    model = train_model(\n",
        "        model,\n",
        "        train_data,\n",
        "        val_data,\n",
        "        seq_len=360,\n",
        "        pred_len=60,\n",
        "        batch_size=32,    # reduced from 64\n",
        "        epochs=5,        # increased from 5\n",
        "        lr=1e-4           # decreased from 1e-3\n",
        "    )\n",
        "\n",
        "    print(\"Evaluating model...\")\n",
        "    evaluate_model(model, test_data, seq_len=360, pred_len=60)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qhzp0MdCes-r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}