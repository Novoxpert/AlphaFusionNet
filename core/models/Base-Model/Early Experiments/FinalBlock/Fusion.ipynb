{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT_VZ7WkEYeK",
        "outputId": "4dfdd769-0a32-4c02-80ba-99b5cda82acb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Final_Block\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Final_Block/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4b_Zrn6Jawo",
        "outputId": "9b955d61-e00b-44ce-f565-2ae85e8bbc03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fused_embeddings_hierarchical.npy  test_btc_ohlcv.csv\n",
            "fused_embeddings_simple.npy\t   test_embed_ohlcv.csv\n",
            "Fusion.ipynb\t\t\t   test_news_embeddings.pkl\n",
            "news_btc_embeddings.pkl\t\t   timesnet_backbone_embeddings.npy\n",
            "summ_news.csv\t\t\t   timesnet_labels.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "_6rGyU6yEd-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ohlcv_embed = np.load('timesnet_backbone_embeddings.npy')\n",
        "news_embed = pickle.load(open('test_news_embeddings.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "r1IJZlszF9FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_embed = news_embed['embeddings']"
      ],
      "metadata": {
        "id": "rUSiTtG3GPg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ohlcv_embed.shape)\n",
        "print(news_embed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQMs90PzGVYS",
        "outputId": "b1f62322-04df-45ae-daf2-609f699c3fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3195, 49, 768)\n",
            "(3195, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ohlcv_embed = ohlcv_embed[:, -1:, :]"
      ],
      "metadata": {
        "id": "w8NRndqeHBIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ohlcv_embed.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaqZZAKBHTGN",
        "outputId": "ec938604-56bd-4865-cace-85fd84937f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3195, 1, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('test_embed_ohlcv.csv')\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqaoLDF5P4_q",
        "outputId": "bb4bb0fb-bb92-4477-acf6-4d584f37b34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15978 entries, 0 to 15977\n",
            "Data columns (total 8 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   date        15978 non-null  object \n",
            " 1   open        15978 non-null  float64\n",
            " 2   high        15978 non-null  float64\n",
            " 3   low         15978 non-null  float64\n",
            " 4   close       15978 non-null  float64\n",
            " 5   volume      15978 non-null  float64\n",
            " 6   pre_return  15978 non-null  float64\n",
            " 7   return      15978 non-null  float64\n",
            "dtypes: float64(7), object(1)\n",
            "memory usage: 998.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:3195]"
      ],
      "metadata": {
        "id": "34xegFDAQ2mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['future_high'] = df['high'].rolling(window=15).max().shift(-15)\n",
        "df['future_low'] = df['low'].rolling(window=15).min().shift(-15)\n",
        "\n",
        "df['range'] = ((df['future_high'] - df['future_low']) / df['close'] * 100).fillna(0)"
      ],
      "metadata": {
        "id": "l1gKBB29QlTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['range'].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLUDC3QUUcmI",
        "outputId": "6e4b6e0b-993b-4f54-eb3f-dc3b0ce97400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(1.4479785423321856)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_volatility(range_pct):\n",
        "    if pd.isna(range_pct):\n",
        "        return np.nan\n",
        "\n",
        "    if range_pct >= 1:\n",
        "        return 'high_volatility'\n",
        "    else:\n",
        "        return 'normal_volatility'\n",
        "\n",
        "\n",
        "df['label'] = df['range'].apply(lambda x: categorize_volatility(x))"
      ],
      "metadata": {
        "id": "xooLG6H9RBt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "labels = le.fit_transform(labels)\n",
        "print(f\"Encoded data: {labels}\")\n",
        "\n",
        "classes = le.classes_\n",
        "print(f\"Classes: {classes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEE8fY27lmTB",
        "outputId": "27d926cc-e51c-4316-dee1-4f15730dae33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded data: [0 0 1 ... 1 1 1]\n",
            "Classes: ['high_volatility' 'normal_volatility']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels=df['label'].tolist()"
      ],
      "metadata": {
        "id": "_RnKF8fhiyOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnt = 0\n",
        "for i in labels:\n",
        "  if i == 0:\n",
        "    cnt +=1\n",
        "print(cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxbyjrbZT_MC",
        "outputId": "ad8b277f-7612-4ff2-a255-7699180886bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def temporal_pool_concat(ohlcv, news, pool_method='mean'):\n",
        "    \"\"\"Best for capturing both temporal and semantic info\"\"\"\n",
        "\n",
        "    if pool_method == 'mean':\n",
        "        ohlcv_pooled = ohlcv.mean(axis=1)\n",
        "    elif pool_method == 'max':\n",
        "        ohlcv_pooled = ohlcv.max(axis=1)\n",
        "    elif pool_method == 'last':\n",
        "        ohlcv_pooled = ohlcv[:, -1, :]\n",
        "\n",
        "    fused = np.concatenate([ohlcv_pooled, news], axis=1)\n",
        "    return fused\n",
        "\n",
        "fused_simple = temporal_pool_concat(ohlcv_embed, news_embed, pool_method='mean')\n",
        "print(f\"Simple fusion shape: {fused_simple.shape}\")\n",
        "\n",
        "\n",
        "np.save('fused_embeddings_simple.npy', fused_simple)"
      ],
      "metadata": {
        "id": "zLygkShTL97R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5fe27db-073e-4c2b-f9ae-9f040807af37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fusion Results ===\n",
            "Simple fusion shape: (3195, 1536)\n",
            "Smart fusion shape: (3195, 512)\n",
            "Hierarchical fusion shape: (3195, 3072)\n",
            "Attention fusion shape: torch.Size([3195, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "returns = np.load('timesnet_labels.npy')"
      ],
      "metadata": {
        "id": "Qu2PKU9hgSdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "returns[3190]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU5ttuI471w-",
        "outputId": "989a510e-1622-4b04-bb61-28665f1d085a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.353914  ,  6.3462152 ,  6.363626  ,  6.3554354 , -0.5174512 ,\n",
              "         0.03308937, -0.18157104]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_emb_flat = returns.squeeze(1)"
      ],
      "metadata": {
        "id": "WfPpRfx_6aam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_emb_flat[3190]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l14rpNvV8F6L",
        "outputId": "51c700c1-ac87-4c74-f7dc-a5c228d6aac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6.353914  ,  6.3462152 ,  6.363626  ,  6.3554354 , -0.5174512 ,\n",
              "        0.03308937, -0.18157104], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = (label_emb_flat.mean(axis=1) > 0).astype(int)"
      ],
      "metadata": {
        "id": "9WLOehYvhQyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKPX6FzijBrG",
        "outputId": "2db80146-025e-45de-f076-b02d01c8e8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3195,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fused_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei7UX6wuhMfq",
        "outputId": "712e042e-a5df-4e3d-ad69-614c9b46f49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3195, 1536)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "am4B7puBgjzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0DL18Irm3a8",
        "outputId": "b47ecbac-4bbf-487a-a13d-c7ce1cefd263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3195,)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = labels\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    fused_features, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
        "val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.LongTensor(y_val))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "model = MLP(input_dim=fused_features.shape[1], num_classes=len(np.unique(labels)))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 100\n",
        "best_val_acc = 0\n",
        "patience = 10\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_preds = []\n",
        "    val_true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in val_loader:\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_preds.extend(predicted.cpu().numpy())\n",
        "            val_true.extend(batch_y.cpu().numpy())\n",
        "\n",
        "    val_acc = accuracy_score(val_true, val_preds)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "    print(f'Train Loss: {train_loss/len(train_loader):.4f}')\n",
        "    print(f'Val Loss: {val_loss/len(val_loader):.4f}')\n",
        "    print(f'Val Accuracy: {val_acc:.4f}')\n",
        "\n",
        "    # Early stopping\n",
        "    # if val_acc > best_val_acc:\n",
        "    #     best_val_acc = val_acc\n",
        "    #     torch.save(model.state_dict(), 'best_model.pth')\n",
        "    #     patience_counter = 0\n",
        "    # else:\n",
        "    #     patience_counter += 1\n",
        "    #     if patience_counter >= patience:\n",
        "    #         print(f'Early stopping at epoch {epoch+1}')\n",
        "    #         break\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(torch.FloatTensor(X_val))\n",
        "    _, test_preds = torch.max(test_outputs, 1)\n",
        "\n",
        "print(\"\\nFinal Results:\")\n",
        "print(classification_report(y_val, test_preds.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LrdUIkWdNSH",
        "outputId": "e0c3df7a-a03d-474c-ee3f-bab15c04bbb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100:\n",
            "Train Loss: 0.6917\n",
            "Val Loss: 0.6777\n",
            "Val Accuracy: 0.6119\n",
            "Epoch 2/100:\n",
            "Train Loss: 0.5427\n",
            "Val Loss: 0.8137\n",
            "Val Accuracy: 0.5571\n",
            "Epoch 3/100:\n",
            "Train Loss: 0.3389\n",
            "Val Loss: 0.9974\n",
            "Val Accuracy: 0.5571\n",
            "Epoch 4/100:\n",
            "Train Loss: 0.1713\n",
            "Val Loss: 1.5235\n",
            "Val Accuracy: 0.5430\n",
            "Epoch 5/100:\n",
            "Train Loss: 0.1010\n",
            "Val Loss: 1.8875\n",
            "Val Accuracy: 0.5415\n",
            "Epoch 6/100:\n",
            "Train Loss: 0.0761\n",
            "Val Loss: 2.1043\n",
            "Val Accuracy: 0.5430\n",
            "Epoch 7/100:\n",
            "Train Loss: 0.0598\n",
            "Val Loss: 2.2729\n",
            "Val Accuracy: 0.5587\n",
            "Epoch 8/100:\n",
            "Train Loss: 0.0530\n",
            "Val Loss: 2.3347\n",
            "Val Accuracy: 0.5587\n",
            "Epoch 9/100:\n",
            "Train Loss: 0.0349\n",
            "Val Loss: 2.5647\n",
            "Val Accuracy: 0.5571\n",
            "Epoch 10/100:\n",
            "Train Loss: 0.0351\n",
            "Val Loss: 2.7546\n",
            "Val Accuracy: 0.5524\n",
            "Epoch 11/100:\n",
            "Train Loss: 0.0442\n",
            "Val Loss: 2.8071\n",
            "Val Accuracy: 0.5493\n",
            "Epoch 12/100:\n",
            "Train Loss: 0.0341\n",
            "Val Loss: 2.9368\n",
            "Val Accuracy: 0.5243\n",
            "Epoch 13/100:\n",
            "Train Loss: 0.0384\n",
            "Val Loss: 2.7866\n",
            "Val Accuracy: 0.5603\n",
            "Epoch 14/100:\n",
            "Train Loss: 0.0421\n",
            "Val Loss: 2.7099\n",
            "Val Accuracy: 0.5368\n",
            "Epoch 15/100:\n",
            "Train Loss: 0.0382\n",
            "Val Loss: 2.7969\n",
            "Val Accuracy: 0.5603\n",
            "Epoch 16/100:\n",
            "Train Loss: 0.0314\n",
            "Val Loss: 2.8494\n",
            "Val Accuracy: 0.5383\n",
            "Epoch 17/100:\n",
            "Train Loss: 0.0306\n",
            "Val Loss: 2.9620\n",
            "Val Accuracy: 0.5493\n",
            "Epoch 18/100:\n",
            "Train Loss: 0.0432\n",
            "Val Loss: 2.7780\n",
            "Val Accuracy: 0.5524\n",
            "Epoch 19/100:\n",
            "Train Loss: 0.0201\n",
            "Val Loss: 2.9250\n",
            "Val Accuracy: 0.5618\n",
            "Epoch 20/100:\n",
            "Train Loss: 0.0132\n",
            "Val Loss: 3.2510\n",
            "Val Accuracy: 0.5587\n",
            "Epoch 21/100:\n",
            "Train Loss: 0.0117\n",
            "Val Loss: 3.5290\n",
            "Val Accuracy: 0.5571\n",
            "Epoch 22/100:\n",
            "Train Loss: 0.0109\n",
            "Val Loss: 3.8350\n",
            "Val Accuracy: 0.5493\n",
            "Epoch 23/100:\n",
            "Train Loss: 0.0166\n",
            "Val Loss: 3.8255\n",
            "Val Accuracy: 0.5462\n",
            "Epoch 24/100:\n",
            "Train Loss: 0.0258\n",
            "Val Loss: 3.6523\n",
            "Val Accuracy: 0.5540\n",
            "Epoch 25/100:\n",
            "Train Loss: 0.0177\n",
            "Val Loss: 3.7319\n",
            "Val Accuracy: 0.5477\n",
            "Epoch 26/100:\n",
            "Train Loss: 0.0251\n",
            "Val Loss: 3.6884\n",
            "Val Accuracy: 0.5556\n",
            "Epoch 27/100:\n",
            "Train Loss: 0.0244\n",
            "Val Loss: 3.7402\n",
            "Val Accuracy: 0.5540\n",
            "Epoch 28/100:\n",
            "Train Loss: 0.0235\n",
            "Val Loss: 3.6608\n",
            "Val Accuracy: 0.5603\n",
            "Epoch 29/100:\n",
            "Train Loss: 0.0269\n",
            "Val Loss: 3.5859\n",
            "Val Accuracy: 0.5540\n",
            "Epoch 30/100:\n",
            "Train Loss: 0.0236\n",
            "Val Loss: 3.5454\n",
            "Val Accuracy: 0.5649\n",
            "Epoch 31/100:\n",
            "Train Loss: 0.0136\n",
            "Val Loss: 3.8669\n",
            "Val Accuracy: 0.5603\n",
            "Epoch 32/100:\n",
            "Train Loss: 0.0099\n",
            "Val Loss: 3.9999\n",
            "Val Accuracy: 0.5556\n",
            "Epoch 33/100:\n",
            "Train Loss: 0.0073\n",
            "Val Loss: 4.3112\n",
            "Val Accuracy: 0.5493\n",
            "Epoch 34/100:\n",
            "Train Loss: 0.0098\n",
            "Val Loss: 4.3867\n",
            "Val Accuracy: 0.5462\n",
            "Epoch 35/100:\n",
            "Train Loss: 0.0138\n",
            "Val Loss: 4.3109\n",
            "Val Accuracy: 0.5399\n",
            "Epoch 36/100:\n",
            "Train Loss: 0.0114\n",
            "Val Loss: 4.3132\n",
            "Val Accuracy: 0.5477\n",
            "Epoch 37/100:\n",
            "Train Loss: 0.0167\n",
            "Val Loss: 4.2456\n",
            "Val Accuracy: 0.5430\n",
            "Epoch 38/100:\n",
            "Train Loss: 0.0122\n",
            "Val Loss: 4.4509\n",
            "Val Accuracy: 0.5493\n",
            "Epoch 39/100:\n",
            "Train Loss: 0.0219\n",
            "Val Loss: 4.0099\n",
            "Val Accuracy: 0.5462\n",
            "Epoch 40/100:\n",
            "Train Loss: 0.0109\n",
            "Val Loss: 4.1026\n",
            "Val Accuracy: 0.5430\n",
            "Epoch 41/100:\n",
            "Train Loss: 0.0094\n",
            "Val Loss: 4.4470\n",
            "Val Accuracy: 0.5540\n",
            "Epoch 42/100:\n",
            "Train Loss: 0.0164\n",
            "Val Loss: 4.3501\n",
            "Val Accuracy: 0.5493\n",
            "Epoch 43/100:\n",
            "Train Loss: 0.0200\n",
            "Val Loss: 4.4414\n",
            "Val Accuracy: 0.5556\n",
            "Epoch 44/100:\n",
            "Train Loss: 0.0269\n",
            "Val Loss: 3.9016\n",
            "Val Accuracy: 0.5462\n",
            "Epoch 45/100:\n",
            "Train Loss: 0.0154\n",
            "Val Loss: 4.0379\n",
            "Val Accuracy: 0.5462\n",
            "Epoch 46/100:\n",
            "Train Loss: 0.0120\n",
            "Val Loss: 4.4418\n",
            "Val Accuracy: 0.5509\n",
            "Epoch 47/100:\n",
            "Train Loss: 0.0292\n",
            "Val Loss: 3.6387\n",
            "Val Accuracy: 0.5681\n",
            "Epoch 48/100:\n",
            "Train Loss: 0.0190\n",
            "Val Loss: 3.6285\n",
            "Val Accuracy: 0.5712\n",
            "Epoch 49/100:\n",
            "Train Loss: 0.0061\n",
            "Val Loss: 4.0346\n",
            "Val Accuracy: 0.5790\n",
            "Epoch 50/100:\n",
            "Train Loss: 0.0073\n",
            "Val Loss: 4.3510\n",
            "Val Accuracy: 0.5743\n",
            "Epoch 51/100:\n",
            "Train Loss: 0.0052\n",
            "Val Loss: 4.5247\n",
            "Val Accuracy: 0.5775\n",
            "Epoch 52/100:\n",
            "Train Loss: 0.0016\n",
            "Val Loss: 4.6993\n",
            "Val Accuracy: 0.5696\n",
            "Epoch 53/100:\n",
            "Train Loss: 0.0036\n",
            "Val Loss: 4.8110\n",
            "Val Accuracy: 0.5556\n",
            "Epoch 54/100:\n",
            "Train Loss: 0.0067\n",
            "Val Loss: 4.8141\n",
            "Val Accuracy: 0.5587\n",
            "Epoch 55/100:\n",
            "Train Loss: 0.0158\n",
            "Val Loss: 4.8808\n",
            "Val Accuracy: 0.5634\n",
            "Epoch 56/100:\n",
            "Train Loss: 0.0072\n",
            "Val Loss: 4.8564\n",
            "Val Accuracy: 0.5603\n",
            "Epoch 57/100:\n",
            "Train Loss: 0.0186\n",
            "Val Loss: 4.5932\n",
            "Val Accuracy: 0.5415\n",
            "Epoch 58/100:\n",
            "Train Loss: 0.0250\n",
            "Val Loss: 4.1456\n",
            "Val Accuracy: 0.5462\n",
            "Epoch 59/100:\n",
            "Train Loss: 0.0206\n",
            "Val Loss: 3.8880\n",
            "Val Accuracy: 0.5681\n",
            "Epoch 60/100:\n",
            "Train Loss: 0.0143\n",
            "Val Loss: 4.2133\n",
            "Val Accuracy: 0.5634\n",
            "Epoch 61/100:\n",
            "Train Loss: 0.0171\n",
            "Val Loss: 4.1778\n",
            "Val Accuracy: 0.5524\n",
            "Epoch 62/100:\n",
            "Train Loss: 0.0110\n",
            "Val Loss: 4.2198\n",
            "Val Accuracy: 0.5462\n",
            "Epoch 63/100:\n",
            "Train Loss: 0.0104\n",
            "Val Loss: 4.3812\n",
            "Val Accuracy: 0.5462\n",
            "Epoch 64/100:\n",
            "Train Loss: 0.0136\n",
            "Val Loss: 4.2402\n",
            "Val Accuracy: 0.5305\n",
            "Epoch 65/100:\n",
            "Train Loss: 0.0079\n",
            "Val Loss: 4.4245\n",
            "Val Accuracy: 0.5336\n",
            "Epoch 66/100:\n",
            "Train Loss: 0.0072\n",
            "Val Loss: 4.7063\n",
            "Val Accuracy: 0.5336\n",
            "Epoch 67/100:\n",
            "Train Loss: 0.0106\n",
            "Val Loss: 4.6817\n",
            "Val Accuracy: 0.5399\n",
            "Epoch 68/100:\n",
            "Train Loss: 0.0111\n",
            "Val Loss: 4.5082\n",
            "Val Accuracy: 0.5571\n",
            "Epoch 69/100:\n",
            "Train Loss: 0.0141\n",
            "Val Loss: 4.4805\n",
            "Val Accuracy: 0.5524\n",
            "Epoch 70/100:\n",
            "Train Loss: 0.0092\n",
            "Val Loss: 4.7171\n",
            "Val Accuracy: 0.5462\n",
            "Epoch 71/100:\n",
            "Train Loss: 0.0095\n",
            "Val Loss: 4.8656\n",
            "Val Accuracy: 0.5556\n",
            "Epoch 72/100:\n",
            "Train Loss: 0.0097\n",
            "Val Loss: 5.0781\n",
            "Val Accuracy: 0.5743\n",
            "Epoch 73/100:\n",
            "Train Loss: 0.0066\n",
            "Val Loss: 5.1512\n",
            "Val Accuracy: 0.5274\n",
            "Epoch 74/100:\n",
            "Train Loss: 0.0040\n",
            "Val Loss: 5.5309\n",
            "Val Accuracy: 0.5336\n",
            "Epoch 75/100:\n",
            "Train Loss: 0.0074\n",
            "Val Loss: 5.6837\n",
            "Val Accuracy: 0.5290\n",
            "Epoch 76/100:\n",
            "Train Loss: 0.0072\n",
            "Val Loss: 5.6442\n",
            "Val Accuracy: 0.5290\n",
            "Epoch 77/100:\n",
            "Train Loss: 0.0187\n",
            "Val Loss: 5.0297\n",
            "Val Accuracy: 0.5462\n",
            "Epoch 78/100:\n",
            "Train Loss: 0.0082\n",
            "Val Loss: 5.2268\n",
            "Val Accuracy: 0.5540\n",
            "Epoch 79/100:\n",
            "Train Loss: 0.0062\n",
            "Val Loss: 5.3870\n",
            "Val Accuracy: 0.5634\n",
            "Epoch 80/100:\n",
            "Train Loss: 0.0177\n",
            "Val Loss: 4.7421\n",
            "Val Accuracy: 0.5524\n",
            "Epoch 81/100:\n",
            "Train Loss: 0.0133\n",
            "Val Loss: 4.4757\n",
            "Val Accuracy: 0.5493\n",
            "Epoch 82/100:\n",
            "Train Loss: 0.0177\n",
            "Val Loss: 4.6803\n",
            "Val Accuracy: 0.5446\n",
            "Epoch 83/100:\n",
            "Train Loss: 0.0144\n",
            "Val Loss: 4.8448\n",
            "Val Accuracy: 0.5618\n",
            "Epoch 84/100:\n",
            "Train Loss: 0.0065\n",
            "Val Loss: 5.1285\n",
            "Val Accuracy: 0.5571\n",
            "Epoch 85/100:\n",
            "Train Loss: 0.0060\n",
            "Val Loss: 5.1338\n",
            "Val Accuracy: 0.5415\n",
            "Epoch 86/100:\n",
            "Train Loss: 0.0052\n",
            "Val Loss: 5.4590\n",
            "Val Accuracy: 0.5336\n",
            "Epoch 87/100:\n",
            "Train Loss: 0.0066\n",
            "Val Loss: 5.6044\n",
            "Val Accuracy: 0.5368\n",
            "Epoch 88/100:\n",
            "Train Loss: 0.0066\n",
            "Val Loss: 5.7213\n",
            "Val Accuracy: 0.5368\n",
            "Epoch 89/100:\n",
            "Train Loss: 0.0082\n",
            "Val Loss: 5.7135\n",
            "Val Accuracy: 0.5477\n",
            "Epoch 90/100:\n",
            "Train Loss: 0.0095\n",
            "Val Loss: 5.4888\n",
            "Val Accuracy: 0.5430\n",
            "Epoch 91/100:\n",
            "Train Loss: 0.0120\n",
            "Val Loss: 5.0716\n",
            "Val Accuracy: 0.5399\n",
            "Epoch 92/100:\n",
            "Train Loss: 0.0081\n",
            "Val Loss: 5.1562\n",
            "Val Accuracy: 0.5430\n",
            "Epoch 93/100:\n",
            "Train Loss: 0.0050\n",
            "Val Loss: 5.2986\n",
            "Val Accuracy: 0.5399\n",
            "Epoch 94/100:\n",
            "Train Loss: 0.0041\n",
            "Val Loss: 5.5586\n",
            "Val Accuracy: 0.5415\n",
            "Epoch 95/100:\n",
            "Train Loss: 0.0073\n",
            "Val Loss: 5.6657\n",
            "Val Accuracy: 0.5336\n",
            "Epoch 96/100:\n",
            "Train Loss: 0.0084\n",
            "Val Loss: 5.7419\n",
            "Val Accuracy: 0.5399\n",
            "Epoch 97/100:\n",
            "Train Loss: 0.0127\n",
            "Val Loss: 5.7527\n",
            "Val Accuracy: 0.5321\n",
            "Epoch 98/100:\n",
            "Train Loss: 0.0089\n",
            "Val Loss: 5.6228\n",
            "Val Accuracy: 0.5399\n",
            "Epoch 99/100:\n",
            "Train Loss: 0.0133\n",
            "Val Loss: 5.6416\n",
            "Val Accuracy: 0.5321\n",
            "Epoch 100/100:\n",
            "Train Loss: 0.0086\n",
            "Val Loss: 5.6598\n",
            "Val Accuracy: 0.5509\n",
            "\n",
            "Final Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.99      0.75       383\n",
            "           1       0.33      0.00      0.01       256\n",
            "\n",
            "    accuracy                           0.60       639\n",
            "   macro avg       0.47      0.50      0.38       639\n",
            "weighted avg       0.49      0.60      0.45       639\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wW5MVm9JEpkl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}